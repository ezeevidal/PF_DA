{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas de PurchasesFinal(Eze).csv:\n",
      "           InventoryId  Store  Brand                   Description   Size  \\\n",
      "0    69_MOUNTMEND_8412     69   8412     Tequila Ocho Plata Fresno  750mL   \n",
      "1     30_CULCHETH_5255     30   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "2    34_PITMERDEN_5215     34   5215  TGI Fridays Long Island Iced  1.75L   \n",
      "3  1_HARDERSFIELD_5255      1   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "4    76_DONCASTER_2034     76   2034     Glendalough Double Barrel  750mL   \n",
      "\n",
      "   VendorNumber                   VendorName  PONumber      PODate  \\\n",
      "0           105  ALTAMAR BRANDS LLC               8124  2015-12-21   \n",
      "1          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "2          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "3          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "4           388  ATLANTIC IMPORTING COMPANY       8169  2015-12-24   \n",
      "\n",
      "  ReceivingDate InvoiceDate     PayDate  PurchasePrice  Quantity  Dollars  \\\n",
      "0    2016-01-02  2016-01-04  2016-02-16          35.71         6   214.26   \n",
      "1    2016-01-01  2016-01-07  2016-02-21           9.35         4    37.40   \n",
      "2    2016-01-02  2016-01-07  2016-02-21           9.41         5    47.05   \n",
      "3    2016-01-01  2016-01-07  2016-02-21           9.35         6    56.10   \n",
      "4    2016-01-02  2016-01-09  2016-02-16          21.32         5   106.60   \n",
      "\n",
      "   Classification  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "\n",
      "Primeras filas de SalesFinal(Eze).csv:\n",
      "           InventoryId  Store  Brand                 Description        Size  \\\n",
      "0  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "1  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "2  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "3  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "4  1_HARDERSFIELD_1005      1   1005     Maker's Mark Combo Pack  375mL 2 Pk   \n",
      "\n",
      "   SalesQuantity  SalesDollars  SalesPrice SalesDate  Volume  Classification  \\\n",
      "0              1         16.49       16.49  1/1/2016     750               1   \n",
      "1              2         32.98       16.49  1/2/2016     750               1   \n",
      "2              1         16.49       16.49  1/3/2016     750               1   \n",
      "3              1         14.49       14.49  1/8/2016     750               1   \n",
      "4              2         69.98       34.99  1/9/2016     375               1   \n",
      "\n",
      "   ExciseTax  VendorNo                   VendorName  \n",
      "0       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "1       1.57     12546  JIM BEAM BRANDS COMPANY      \n",
      "2       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "3       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "4       0.79     12546  JIM BEAM BRANDS COMPANY      \n"
     ]
    }
   ],
   "source": [
    "#Cargo los datasets y los analizo\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargo los datasets\n",
    "purchases_df = pd.read_csv('PurchasesFinal(Eze).csv')\n",
    "sales_df = pd.read_csv('SalesFinal(Eze).csv')\n",
    "\n",
    "# Veo las primeras filas de cada dataset para entender su estructura\n",
    "print(\"Primeras filas de PurchasesFinal(Eze).csv:\")\n",
    "print(purchases_df.head())\n",
    "\n",
    "print(\"\\nPrimeras filas de SalesFinal(Eze).csv:\")\n",
    "print(sales_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de valores nulos en PurchasesFinal(Eze).csv:\n",
      "InventoryId       0\n",
      "Store             0\n",
      "Brand             0\n",
      "Description       0\n",
      "Size              3\n",
      "VendorNumber      0\n",
      "VendorName        0\n",
      "PONumber          0\n",
      "PODate            0\n",
      "ReceivingDate     0\n",
      "InvoiceDate       0\n",
      "PayDate           0\n",
      "PurchasePrice     0\n",
      "Quantity          0\n",
      "Dollars           0\n",
      "Classification    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Análisis de valores nulos en SalesFinal(Eze).csv:\n",
      "InventoryId       0\n",
      "Store             0\n",
      "Brand             0\n",
      "Description       0\n",
      "Size              0\n",
      "SalesQuantity     0\n",
      "SalesDollars      0\n",
      "SalesPrice        0\n",
      "SalesDate         0\n",
      "Volume            0\n",
      "Classification    0\n",
      "ExciseTax         0\n",
      "VendorNo          0\n",
      "VendorName        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columnas completamente vacías en PurchasesFinal(Eze).csv:\n",
      "Index([], dtype='object')\n",
      "\n",
      "Columnas completamente vacías en SalesFinal(Eze).csv:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Análisis de datos nulos y vacíos\n",
    "\n",
    "# Verificar valores nulos y vacíos en PurchasesFinal(Eze).csv\n",
    "print(\"Análisis de valores nulos en PurchasesFinal(Eze).csv:\")\n",
    "print(purchases_df.isnull().sum())  # Número de valores nulos por columna\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verificar valores nulos y vacíos en SalesFinal(Eze).csv\n",
    "print(\"Análisis de valores nulos en SalesFinal(Eze).csv:\")\n",
    "print(sales_df.isnull().sum())  # Número de valores nulos por columna\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verificar si existen columnas completamente vacías\n",
    "print(\"Columnas completamente vacías en PurchasesFinal(Eze).csv:\")\n",
    "print(purchases_df.columns[purchases_df.isnull().all()])\n",
    "\n",
    "print(\"\\nColumnas completamente vacías en SalesFinal(Eze).csv:\")\n",
    "print(sales_df.columns[sales_df.isnull().all()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas completamente vacías eliminadas de PurchasesFinal(Eze).csv:\n",
      "Index(['InventoryId', 'Store', 'Brand', 'Description', 'Size', 'VendorNumber',\n",
      "       'VendorName', 'PONumber', 'PODate', 'ReceivingDate', 'InvoiceDate',\n",
      "       'PayDate', 'PurchasePrice', 'Quantity', 'Dollars', 'Classification'],\n",
      "      dtype='object')\n",
      "\n",
      "Columnas completamente vacías eliminadas de SalesFinal(Eze).csv:\n",
      "Index(['InventoryId', 'Store', 'Brand', 'Description', 'Size', 'SalesQuantity',\n",
      "       'SalesDollars', 'SalesPrice', 'SalesDate', 'Volume', 'Classification',\n",
      "       'ExciseTax', 'VendorNo', 'VendorName'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Limpieza de datos\n",
    "\n",
    "#Elimino columnas completamente vacías\n",
    "purchases_df = purchases_df.dropna(axis=1, how='all')\n",
    "sales_df = sales_df.dropna(axis=1, how='all')\n",
    "\n",
    "print(\"Columnas completamente vacías eliminadas de PurchasesFinal(Eze).csv:\")\n",
    "print(purchases_df.columns)\n",
    "\n",
    "print(\"\\nColumnas completamente vacías eliminadas de SalesFinal(Eze).csv:\")\n",
    "print(sales_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ezequiel\\AppData\\Local\\Temp\\ipykernel_12492\\3591464943.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  purchases_df[column].fillna('Desconocido', inplace=True)  # Relleno con un valor fijo\n",
      "C:\\Users\\Ezequiel\\AppData\\Local\\Temp\\ipykernel_12492\\3591464943.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  purchases_df[column].fillna(purchases_df[column].mean(), inplace=True)  # Relleno con el promedio\n",
      "C:\\Users\\Ezequiel\\AppData\\Local\\Temp\\ipykernel_12492\\3591464943.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_df[column].fillna('Desconocido', inplace=True)  # Rellenar con un valor fijo\n",
      "C:\\Users\\Ezequiel\\AppData\\Local\\Temp\\ipykernel_12492\\3591464943.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_df[column].fillna(sales_df[column].mean(), inplace=True)  # Rellenar con el promedio\n"
     ]
    }
   ],
   "source": [
    "#Rellenar valores nulos\n",
    "# Para cada dataset, rellenamos los valores nulos con el promedio (si son numéricos) o un valor fijo (si son categóricos)\n",
    "# Trabajaremos en cada columna según su tipo de dato\n",
    "\n",
    "# Relleno en PurchasesFinal(Eze).csv\n",
    "for column in purchases_df.columns:\n",
    "    if purchases_df[column].dtype in ['int64', 'float64']:  # Si la columna es numérica\n",
    "        purchases_df[column].fillna(purchases_df[column].mean(), inplace=True)  # Relleno con el promedio\n",
    "    else:  # Si la columna no es numérica\n",
    "        purchases_df[column].fillna('Desconocido', inplace=True)  # Relleno con un valor fijo\n",
    "\n",
    "# Relleno en SalesFinal(Eze).csv\n",
    "for column in sales_df.columns:\n",
    "    if sales_df[column].dtype in ['int64', 'float64']:  # Si la columna es numérica\n",
    "        sales_df[column].fillna(sales_df[column].mean(), inplace=True)  # Rellenar con el promedio\n",
    "    else:  # Si la columna no es numérica\n",
    "        sales_df[column].fillna('Desconocido', inplace=True)  # Rellenar con un valor fijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificar valores nulos después de rellenar (PurchasesFinal):\n",
      "InventoryId       0\n",
      "Store             0\n",
      "Brand             0\n",
      "Description       0\n",
      "Size              0\n",
      "VendorNumber      0\n",
      "VendorName        0\n",
      "PONumber          0\n",
      "PODate            0\n",
      "ReceivingDate     0\n",
      "InvoiceDate       0\n",
      "PayDate           0\n",
      "PurchasePrice     0\n",
      "Quantity          0\n",
      "Dollars           0\n",
      "Classification    0\n",
      "dtype: int64\n",
      "\n",
      "Verificar valores nulos después de rellenar (SalesFinal):\n",
      "InventoryId       0\n",
      "Store             0\n",
      "Brand             0\n",
      "Description       0\n",
      "Size              0\n",
      "SalesQuantity     0\n",
      "SalesDollars      0\n",
      "SalesPrice        0\n",
      "SalesDate         0\n",
      "Volume            0\n",
      "Classification    0\n",
      "ExciseTax         0\n",
      "VendorNo          0\n",
      "VendorName        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirmo que no queden valores nulos\n",
    "print(\"\\nVerificar valores nulos después de rellenar (PurchasesFinal):\")\n",
    "print(purchases_df.isnull().sum())\n",
    "\n",
    "print(\"\\nVerificar valores nulos después de rellenar (SalesFinal):\")\n",
    "print(sales_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets limpios guardados como PurchasesFinal_Cleaned.csv y SalesFinal_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Paso 3: Guardo los datasets limpios\n",
    "purchases_df.to_csv('PurchasesFinal_Cleaned.csv', index=False)\n",
    "sales_df.to_csv('SalesFinal_Cleaned.csv', index=False)\n",
    "print(\"\\nDatasets limpios guardados como PurchasesFinal_Cleaned.csv y SalesFinal_Cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
